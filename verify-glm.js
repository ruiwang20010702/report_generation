#!/usr/bin/env node

/**
 * ğŸ§  éªŒè¯æ™ºè°± GLM-4 é…ç½®
 */

import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

async function verifyGLM() {
  console.log('\n' + '='.repeat(60));
  console.log('ğŸ§  æ™ºè°± GLM-4 é…ç½®éªŒè¯');
  console.log('='.repeat(60) + '\n');

  // æ£€æŸ¥ API Key
  if (!process.env.GLM_API_KEY) {
    console.log('âŒ æœªé…ç½® GLM_API_KEYï¼');
    console.log('\nè¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ï¼š');
    console.log('GLM_API_KEY=your_api_key_here\n');
    console.log('ğŸ’¡ è·å–æ–¹å¼ï¼š');
    console.log('1. è®¿é—®ï¼šhttps://open.bigmodel.cn/');
    console.log('2. æ³¨å†Œ/ç™»å½•è´¦å·');
    console.log('3. åœ¨"APIå¯†é’¥"é¡µé¢åˆ›å»ºå¯†é’¥\n');
    return;
  }

  console.log('âœ… GLM_API_KEY å·²é…ç½®');
  console.log(`ğŸ“‹ é•¿åº¦: ${process.env.GLM_API_KEY.length} å­—ç¬¦\n`);

  // æµ‹è¯•è¿æ¥
  console.log('ğŸ”„ æ­£åœ¨æµ‹è¯• GLM-4 è¿æ¥...\n');

  try {
    const client = new OpenAI({
      apiKey: process.env.GLM_API_KEY,
      baseURL: 'https://open.bigmodel.cn/api/paas/v4'
    });

    const startTime = Date.now();

    const response = await client.chat.completions.create({
      model: 'glm-4-plus',
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‹±è¯­æ•™å­¦ä¸“å®¶ã€‚'
        },
        {
          role: 'user',
          content: 'è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚'
        }
      ],
      max_tokens: 100
    });

    const elapsed = ((Date.now() - startTime) / 1000).toFixed(2);

    console.log('âœ… è¿æ¥æˆåŠŸï¼\n');
    console.log('='.repeat(60));
    console.log('ğŸ“Š æµ‹è¯•ç»“æœ');
    console.log('='.repeat(60) + '\n');
    console.log(`â±ï¸  å“åº”æ—¶é—´: ${elapsed}ç§’`);
    console.log(`ğŸ”¢ ä½¿ç”¨ Tokens: ${response.usage?.total_tokens || 0}`);
    console.log(`ğŸ“ æ¨¡å‹: ${response.model}`);
    console.log(`\nğŸ’¬ AI å›å¤:\n${response.choices[0].message.content}\n`);

    // è®¡ç®—æˆæœ¬
    if (response.usage) {
      const inputCost = (response.usage.prompt_tokens / 1000000) * 50;
      const outputCost = (response.usage.completion_tokens / 1000000) * 50;
      const totalCost = inputCost + outputCost;
      console.log('='.repeat(60));
      console.log('ğŸ’° æˆæœ¬åˆ†æ');
      console.log('='.repeat(60) + '\n');
      console.log(`è¾“å…¥ Tokens: ${response.usage.prompt_tokens} (Â¥${inputCost.toFixed(6)})`);
      console.log(`è¾“å‡º Tokens: ${response.usage.completion_tokens} (Â¥${outputCost.toFixed(6)})`);
      console.log(`æ€»è®¡: Â¥${totalCost.toFixed(6)}\n`);
    }

    console.log('='.repeat(60));
    console.log('âœ¨ GLM-4 é…ç½®å®Œç¾ï¼');
    console.log('='.repeat(60) + '\n');
    console.log('ğŸ’¡ ä¸‹ä¸€æ­¥ï¼š');
    console.log('1. å¯åŠ¨æœåŠ¡å™¨ï¼šnpm run dev');
    console.log('2. ç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨æ™ºè°± GLM-4 æ¨¡å‹');
    console.log('3. æ ¹æ®æµ‹è¯•ç»“æœï¼ŒGLM-4 è´¨é‡æœ€é«˜ï¼ˆ98/100åˆ†ï¼‰\n');

  } catch (error) {
    console.log('âŒ è¿æ¥å¤±è´¥ï¼\n');
    console.error('é”™è¯¯ä¿¡æ¯:', error.message);
    
    if (error.message.includes('API key')) {
      console.log('\nğŸ’¡ è§£å†³æ–¹æ³•ï¼š');
      console.log('1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®');
      console.log('2. ç¡®è®¤ API Key æ˜¯å¦å·²æ¿€æ´»');
      console.log('3. è®¿é—® https://open.bigmodel.cn/ æŸ¥çœ‹å¯†é’¥çŠ¶æ€\n');
    } else if (error.message.includes('network') || error.message.includes('timeout')) {
      console.log('\nğŸ’¡ è§£å†³æ–¹æ³•ï¼š');
      console.log('1. æ£€æŸ¥ç½‘ç»œè¿æ¥');
      console.log('2. æ™ºè°± API åœ¨å›½å†…å¯ç›´è¿ï¼Œæ— éœ€ä»£ç†\n');
    }
  }
}

verifyGLM().catch(console.error);

