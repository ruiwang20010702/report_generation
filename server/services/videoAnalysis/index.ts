/**
 * ğŸ“¹ è§†é¢‘åˆ†ææœåŠ¡
 * 
 * è¿™æ˜¯é‡æ„åçš„ä¸»å…¥å£æ–‡ä»¶ï¼Œå°†åŸæ¥ 3600+ è¡Œçš„ä»£ç æ‹†åˆ†æˆå¤šä¸ªæ¨¡å—ï¼š
 * - config.ts: AIé…ç½®ã€å®šä»·ã€æŠ¥å‘Šå­—æ•°é…ç½®
 * - aiClient.ts: AIå®¢æˆ·ç«¯ç®¡ç†
 * - transcriptionAnalyzer.ts: è½¬å½•åˆ†æé€»è¾‘
 * - reportGenerator.ts: å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆ
 * - dataValidator.ts: æ•°æ®éªŒè¯å’Œä¿®å¤
 * - mockData.ts: Mockæ•°æ®
 * - types.ts: ç±»å‹å®šä¹‰
 */

import OpenAI from 'openai';
import { VideoAnalysisRequest, VideoAnalysisResponse } from '../../types/index.js';
import { WhisperService } from '../whisperService.js';
import { tingwuTranscriptionService } from '../tingwuTranscriptionService.js';
import { reportRecordService } from '../reportRecordService.js';
import type { ReportRecordMeta } from '../reportRecordService.js';
import { AppError, ErrorType } from '../../utils/errors.js';

// å¯¼å…¥æ‹†åˆ†çš„æ¨¡å—
import { detectAIProvider, createAIClient, getOpenAIClient } from './aiClient.js';
import { transcribeVideoSmart, analyzeTranscriptionWithGPT } from './transcriptionAnalyzer.js';
import { compareVideos } from './reportGenerator.js';
import { analyzeMock } from './mockData.js';

export class VideoAnalysisService {
  private defaultOpenai: OpenAI | null;
  private defaultUseMock: boolean;
  private whisperService: WhisperService;

  constructor() {
    this.whisperService = new WhisperService();
    
    // ğŸŒŸ å¼ºåˆ¶ä½¿ç”¨ GLM æ¨¡å‹ï¼ˆå›ºå®šé…ç½®ï¼‰
    try {
      const aiProvider = detectAIProvider();
      if (aiProvider) {
        this.defaultOpenai = createAIClient(aiProvider);
        this.defaultUseMock = false;
      } else {
        // æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ Mock
        if (process.env.USE_MOCK_ANALYSIS === 'true') {
          console.log('âš ï¸  Default mode: MOCK - using simulated data');
          console.log('ğŸ’¡ Users can provide their own API Key in the form for real AI analysis');
          this.defaultOpenai = null;
          this.defaultUseMock = true;
        } else {
          throw new Error('GLM API Key æœªé…ç½®ä¸”æœªå¯ç”¨ Mock æ¨¡å¼');
        }
      }
    } catch (error) {
      console.error('âŒ AI æœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error instanceof Error ? error.message : error);
      // è½¬æ¢ä¸ºAppError
      if (error instanceof AppError) {
        throw error;
      }
      throw new AppError(
        ErrorType.API_KEY_ERROR,
        error instanceof Error ? error.message : 'AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥',
        {
          originalError: error instanceof Error ? error : undefined,
          userMessage: 'AIæœåŠ¡é…ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥è®¾ç½®',
        }
      );
    }
  }

  /**
   * ä¸»è¦çš„åˆ†ææ–¹æ³•
   */
  async analyzeVideos(request: VideoAnalysisRequest): Promise<VideoAnalysisResponse> {
    // åˆ¤æ–­æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    const useMock = request.useMockData !== false && (request.useMockData || (!request.apiKey && this.defaultUseMock));
    
    if (useMock) {
      console.log('ğŸ“ Using mock analysis for:', request.studentName);
      return analyzeMock(request);
    }

    // è·å– AI å®¢æˆ·ç«¯ï¼ˆGLMï¼‰
    const openai = getOpenAIClient(request.apiKey, this.defaultOpenai);
    if (!openai) {
      throw new AppError(
        ErrorType.API_KEY_ERROR,
        'No GLM API key available',
        {
          userMessage: 'æœªæä¾›GLM APIå¯†é’¥ã€‚è¯·æä¾›GLM APIå¯†é’¥æˆ–ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼ã€‚',
          context: { studentName: request.studentName },
        }
      );
    }

    try {
      console.log('ğŸš€ Starting real AI video analysis for:', request.studentName);
      console.log('ğŸ“¹ Video 1:', request.video1);
      console.log('ğŸ“¹ Video 2:', request.video2);

      // ğŸš€ è¶…çº§å¹¶è¡Œï¼šè®©æ‰€æœ‰å¯å¹¶è¡Œçš„æ­¥éª¤éƒ½å¹¶è¡Œæ‰§è¡Œ
      console.log('\n=== ğŸš€ è¶…çº§å¹¶è¡Œåˆ†æï¼šä¸‹è½½ã€è½¬å½•ã€åˆ†æå…¨éƒ¨å¹¶è¡Œ ===');
      const overallStartTime = Date.now();
      
      // è§†é¢‘å¤„ç†çŠ¶æ€è·Ÿè¸ª
      const videoStatus = {
        video1: { transcribing: false, analyzing: false, completed: false },
        video2: { transcribing: false, analyzing: false, completed: false }
      };
      
      // æ·»åŠ è¿›åº¦ç›‘æ§
      const progressInterval = setInterval(() => {
        const elapsed = ((Date.now() - overallStartTime) / 1000).toFixed(0);
        const v1Status = videoStatus.video1.completed ? 'âœ… å·²å®Œæˆ' : 
                        videoStatus.video1.analyzing ? 'ğŸ¤– åˆ†æä¸­' :
                        videoStatus.video1.transcribing ? 'ğŸ“ è½¬å½•ä¸­' : 'â³ ç­‰å¾…ä¸­';
        const v2Status = videoStatus.video2.completed ? 'âœ… å·²å®Œæˆ' : 
                        videoStatus.video2.analyzing ? 'ğŸ¤– åˆ†æä¸­' :
                        videoStatus.video2.transcribing ? 'ğŸ“ è½¬å½•ä¸­' : 'â³ ç­‰å¾…ä¸­';
        console.log(`â³ è§†é¢‘åˆ†æè¿›è¡Œä¸­... å·²è€—æ—¶: ${elapsed}ç§’ | è§†é¢‘1: ${v1Status} | è§†é¢‘2: ${v2Status}`);
      }, 15000);
      
      let video1Result, video2Result;
      try {
        console.log('\nğŸ¯ [æµæ°´çº¿] è½¬å½•å’Œåˆ†ææµæ°´çº¿æ‰§è¡Œ...');
        const transcribeStartTime = Date.now();
        
        const transcriptionLanguage = request.language || process.env.TINGWU_LANGUAGE || 'en';
        console.log(`ğŸŒ ä½¿ç”¨è½¬å½•è¯­è¨€: ${transcriptionLanguage}`);
        const requestedSpeakerCount = request.speakerCount ?? 3;
        console.log(`ğŸ‘¥ è¯´è¯äººæ•°é‡: ${requestedSpeakerCount}`);

        const [result1, result2] = await Promise.all([
          (async () => {
            console.log('ğŸ“¥ [è§†é¢‘1] å¼€å§‹è½¬å½•...');
            videoStatus.video1.transcribing = true;
            const transcription1 = await transcribeVideoSmart(
              request.video1,
              'Video 1',
              transcriptionLanguage,
              requestedSpeakerCount
            );
            console.log('âœ… [è§†é¢‘1] è½¬å½•å®Œæˆ');
            
            if (!transcription1.text || transcription1.text.trim().length === 0) {
              throw new AppError(
                ErrorType.TRANSCRIPTION_ERROR,
                'ç¬¬ä¸€ä¸ªè§†é¢‘è½¬å½•å¤±è´¥ï¼šæœªæå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹',
                {
                  userMessage: 'ç¬¬ä¸€ä¸ªè§†é¢‘è½¬å½•å¤±è´¥ï¼šæœªæå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹ã€‚',
                  context: { studentName: request.studentName, videoNumber: 1 },
                }
              );
            }
            console.log(`ğŸ“ [è§†é¢‘1] è½¬å½•æ–‡æœ¬é•¿åº¦: ${transcription1.text.length} å­—ç¬¦`);
            
            videoStatus.video1.transcribing = false;
            videoStatus.video1.analyzing = true;
            console.log('ğŸ¤– [è§†é¢‘1] å¼€å§‹åˆ†æ...');
            const analysis1Text = await analyzeTranscriptionWithGPT(transcription1, openai, 'Video 1', this.whisperService);
            console.log('âœ… [è§†é¢‘1] åˆ†æå®Œæˆ');
            videoStatus.video1.analyzing = false;
            videoStatus.video1.completed = true;
            
            return { 
              transcription: transcription1, 
              analysis: analysis1Text.analysis,
              usage: analysis1Text.usage
            };
          })(),
          (async () => {
            console.log('ğŸ“¥ [è§†é¢‘2] å¼€å§‹è½¬å½•...');
            videoStatus.video2.transcribing = true;
            const transcription2 = await transcribeVideoSmart(
              request.video2,
              'Video 2',
              transcriptionLanguage,
              requestedSpeakerCount
            );
            console.log('âœ… [è§†é¢‘2] è½¬å½•å®Œæˆ');
            
            if (!transcription2.text || transcription2.text.trim().length === 0) {
              throw new AppError(
                ErrorType.TRANSCRIPTION_ERROR,
                'ç¬¬äºŒä¸ªè§†é¢‘è½¬å½•å¤±è´¥ï¼šæœªæå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹',
                {
                  userMessage: 'ç¬¬äºŒä¸ªè§†é¢‘è½¬å½•å¤±è´¥ï¼šæœªæå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹ã€‚',
                  context: { studentName: request.studentName, videoNumber: 2 },
                }
              );
            }
            console.log(`ğŸ“ [è§†é¢‘2] è½¬å½•æ–‡æœ¬é•¿åº¦: ${transcription2.text.length} å­—ç¬¦`);
            
            videoStatus.video2.transcribing = false;
            videoStatus.video2.analyzing = true;
            console.log('ğŸ¤– [è§†é¢‘2] å¼€å§‹åˆ†æ...');
            const analysis2Text = await analyzeTranscriptionWithGPT(transcription2, openai, 'Video 2', this.whisperService);
            console.log('âœ… [è§†é¢‘2] åˆ†æå®Œæˆ');
            videoStatus.video2.analyzing = false;
            videoStatus.video2.completed = true;
            
            return { 
              transcription: transcription2, 
              analysis: analysis2Text.analysis,
              usage: analysis2Text.usage
            };
          })()
        ]);
        
        video1Result = result1;
        video2Result = result2;
        
        const totalTime = ((Date.now() - overallStartTime) / 1000).toFixed(1);
        console.log(`âœ… æ‰€æœ‰è§†é¢‘è½¬å½•å’Œåˆ†æå®Œæˆï¼æ€»è€—æ—¶: ${totalTime}ç§’`);
        console.log(`ğŸ’° å½“å‰é€šä¹‰å¬æ‚Ÿå‰©ä½™å…è´¹é¢åº¦: ${tingwuTranscriptionService.getStats().remainingMinutes} åˆ†é’Ÿ/å¤©\n`);
        
        clearInterval(progressInterval);
      } catch (error) {
        clearInterval(progressInterval);
        throw error;
      }

      // 3. æ¯”è¾ƒå¹¶ç”ŸæˆæŠ¥å‘Š
      console.log('\n=== ğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š ===');
      const reportStartTime = Date.now();
      const report = await compareVideos(
        video1Result,
        video2Result,
        {
          studentName: request.studentName,
          studentId: request.studentId,
          grade: request.grade,
          level: request.level,
          unit: request.unit,
          video1Time: request.video1Time,
          video2Time: request.video2Time
        },
        openai
      );

      const reportTime = ((Date.now() - reportStartTime) / 1000).toFixed(1);
      console.log(`âœ… å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼è€—æ—¶: ${reportTime}ç§’`);
      console.log('âœ… æ•´ä½“åˆ†æå®Œæˆ for:', request.studentName);
      
      // è®°å½•æŠ¥å‘Šåˆ°æ•°æ®åº“
      let savedReportMeta: ReportRecordMeta | null = null;

      if (report.costBreakdown) {
        const combinedTranscript = [
          `=== ç¬¬ä¸€ä¸ªè§†é¢‘è½¬å½• (${request.video1Time || 'æœªçŸ¥æ—¶é—´'}) ===`,
          video1Result.transcription.text,
          '',
          `=== ç¬¬äºŒä¸ªè§†é¢‘è½¬å½• (${request.video2Time || 'æœªçŸ¥æ—¶é—´'}) ===`,
          video2Result.transcription.text
        ].join('\n');
        
        const totalDuration = (video1Result.transcription.duration || 0) + (video2Result.transcription.duration || 0);
        
        try {
          savedReportMeta = await reportRecordService.recordReport({
            userId: request.userId,
            studentName: request.studentName,
            studentId: request.studentId,
            videoUrl: `${request.video1};${request.video2}`,
            transcript: combinedTranscript,
            audioDur: Math.round(totalDuration),
            fileName: `${request.studentName}_${new Date().toISOString().split('T')[0]}`,
            fileUrl: request.video1,
            costDetail: report.costBreakdown,
            analysisData: report
          });
        } catch (err) {
          console.error('âš ï¸ æŠ¥å‘Šè®°å½•ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰:', err);
        }
      }
      
      const finalReport = savedReportMeta
        ? {
            ...report,
            reportId: savedReportMeta.id,
            generatedAt: savedReportMeta.createdAt,
          }
        : report;
      
      return finalReport;
    } catch (error) {
      console.error('âŒ Error in analyzeVideos:', error);
      
      if (error instanceof AppError) {
        throw error;
      }
      
      const errorMessage = error instanceof Error ? error.message : String(error);
      let errorType = ErrorType.INTERNAL_ERROR;
      let userMessage = 'è§†é¢‘åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•';
      
      if (errorMessage.includes('transcribe') || errorMessage.includes('è½¬å½•')) {
        errorType = ErrorType.TRANSCRIPTION_ERROR;
        userMessage = 'è§†é¢‘è½¬å½•å¤±è´¥ï¼Œè¯·ç¡®ä¿è§†é¢‘é“¾æ¥å¯è®¿é—®ï¼Œä¸”åŒ…å«éŸ³é¢‘å†…å®¹';
      } else if (errorMessage.includes('API key') || errorMessage.includes('API Key')) {
        errorType = ErrorType.API_KEY_ERROR;
        userMessage = 'APIå¯†é’¥æ— æ•ˆæˆ–æœªé…ç½®ï¼Œè¯·æ£€æŸ¥é…ç½®';
      } else if (errorMessage.includes('download') || errorMessage.includes('ä¸‹è½½')) {
        errorType = ErrorType.VIDEO_PROCESSING_ERROR;
        userMessage = 'è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è§†é¢‘é“¾æ¥æ˜¯å¦æ­£ç¡®';
      } else if (errorMessage.includes('timeout') || errorMessage.includes('è¶…æ—¶')) {
        errorType = ErrorType.TIMEOUT_ERROR;
        userMessage = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·å°è¯•ä½¿ç”¨è¾ƒçŸ­çš„è§†é¢‘ï¼ˆå»ºè®®3-5åˆ†é’Ÿï¼‰';
      }
      
      throw new AppError(
        errorType,
        errorMessage,
        {
          originalError: error instanceof Error ? error : undefined,
          userMessage,
          context: { studentName: request.studentName },
        }
      );
    }
  }
}

// å¯¼å‡ºæœåŠ¡å®ä¾‹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
export { VideoAnalysisService as default };

