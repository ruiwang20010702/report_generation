/**
 * ğŸ“ è§†é¢‘åˆ†ææœåŠ¡é…ç½®
 * åŒ…å«æŠ¥å‘Šå­—æ•°é…ç½®ã€AIæä¾›å•†é…ç½®ã€å®šä»·ç­‰
 */

/**
 * ğŸ“ æŠ¥å‘Šå­—æ•°é…ç½®
 * åœ¨è¿™é‡Œä¿®æ”¹æŠ¥å‘Šå„éƒ¨åˆ†çš„å­—æ•°è¦æ±‚
 */
export const REPORT_WORD_COUNT = {
  // å­¦ä¹ æ•°æ®åˆ†æ
  learningData: {
    handRaising: 50,      // ä¸»åŠ¨å‘è¨€æ¬¡æ•°åˆ†æ
    answerLength: 50,    // å›ç­”é•¿åº¦åˆ†æ
    completeSentences: 50, // å®Œæ•´å¥å­ç‡åˆ†æ
    readingAccuracy: 50,  // é˜…è¯»å‡†ç¡®ç‡åˆ†æ
  },
  // è¿›æ­¥ç»´åº¦
  progressDimensions: {
    fluency: 100,           // æµåˆ©åº¦åˆ†æ
    confidence: 100,        // è‡ªä¿¡å¿ƒåˆ†æ
    languageApplication: 100, // è¯­è¨€åº”ç”¨åˆ†æ
    sentenceComplexity: 100,  // å¥å­å¤æ‚åº¦åˆ†æ
  },
  // æ”¹è¿›é¢†åŸŸ
  improvementAreas: {
    overview: 25,          // æ¦‚è¿°éƒ¨åˆ†
    details: 150,           // è¯¦ç»†åˆ†æéƒ¨åˆ†
    suggestion: 100,        // å»ºè®®æè¿°
  },
};

/**
 * ğŸ¯ AI æä¾›å•†é…ç½®æ¥å£
 */
export interface AIProviderConfig {
  name: string;           // æä¾›å•†æ ‡è¯†ï¼š'DeepSeek' | 'GLM' | 'Qwen' | 'OpenAI'
  apiKey: string;         // API å¯†é’¥
  baseURL?: string;       // API åŸºç¡€ URLï¼ˆå¯é€‰ï¼ŒOpenAI ä½¿ç”¨é»˜è®¤ï¼‰
  model: string;          // æ¨¡å‹åç§°
  displayName: string;    // æ˜¾ç¤ºåç§°
  emoji: string;          // å›¾æ ‡
  features: string[];     // ç‰¹æ€§åˆ—è¡¨
}

/**
 * ğŸ’° AI æ¨¡å‹å®šä»·é…ç½®ï¼ˆ2025å¹´4æœˆæ›´æ–°ï¼‰
 * å•ä½ï¼šå…ƒ/1K tokens
 * æ³¨æ„ï¼šæ™ºè°±GLM-4-Plusåœ¨2025å¹´4æœˆ24æ—¥å¤§å¹…é™ä»·ï¼Œä»Â¥50/1Mé™è‡³Â¥5/1M tokens
 */
export const AI_PRICING: Record<string, { input: number; output: number }> = {
  'glm-4-plus': { input: 0.005, output: 0.005 },   // æ™ºè°±GLM-4-Plus: Â¥5/1M tokens (2025å¹´4æœˆé™ä»·å)
  'glm-4': { input: 0.1, output: 0.1 },             // æ™ºè°±GLM-4: Â¥100/1M tokens
  'deepseek-chat': { input: 0.001, output: 0.002 }, // DeepSeek: Â¥1/1M input, Â¥2/1M output
  'qwen-plus': { input: 0.004, output: 0.012 },     // é€šä¹‰åƒé—®Plus: Â¥4/1M input, Â¥12/1M output
  'gpt-4o': { input: 2.5, output: 10 },             // GPT-4o: $2.5/1M input, $10/1M output (æŒ‰Â¥1=$1è®¡ç®—)
};

/**
 * ğŸ’° è®¡ç®— AI è°ƒç”¨æˆæœ¬
 */
export function calculateAICost(model: string, promptTokens: number, completionTokens: number): number {
  const pricing = AI_PRICING[model] || { input: 0.005, output: 0.005 }; // é»˜è®¤ä½¿ç”¨GLM-4-Pluså®šä»·ï¼ˆ2025å¹´4æœˆé™ä»·åï¼‰
  const inputCost = (promptTokens / 1000) * pricing.input;
  const outputCost = (completionTokens / 1000) * pricing.output;
  return inputCost + outputCost;
}

/**
 * ğŸ“Š åå¤„ç† AI è°ƒç”¨çš„ä½¿ç”¨é‡ç»Ÿè®¡
 */
export interface PostProcessingUsage {
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  cost: number;
  callCount: number;  // å®é™…è°ƒç”¨æ¬¡æ•°
}

/**
 * åˆ›å»ºç©ºçš„ä½¿ç”¨é‡ç»Ÿè®¡å¯¹è±¡
 */
export function createEmptyUsage(): PostProcessingUsage {
  return { promptTokens: 0, completionTokens: 0, totalTokens: 0, cost: 0, callCount: 0 };
}

