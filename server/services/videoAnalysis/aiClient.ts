/**
 * ğŸ¤– AI å®¢æˆ·ç«¯ç®¡ç†æ¨¡å—
 * è´Ÿè´£ AI å®¢æˆ·ç«¯çš„åˆ›å»ºã€é…ç½®å’Œç®¡ç†
 */

import OpenAI from 'openai';
import { HttpsProxyAgent } from 'https-proxy-agent';
import { AppError, ErrorType } from '../../utils/errors.js';
import type { AIProviderConfig } from './config.js';

/**
 * ğŸ” å¼ºåˆ¶ä½¿ç”¨ GLM æ¨¡å‹ï¼ˆå›ºå®šé…ç½®ï¼‰
 * ä¸å†æ”¯æŒé™çº§åˆ°å…¶ä»–æ¨¡å‹ï¼Œç¡®ä¿è¾“å‡ºä¸€è‡´æ€§
 */
export function detectAIProvider(): AIProviderConfig | null {
  // ğŸ§  å¼ºåˆ¶ä½¿ç”¨æ™ºè°± GLM - è´¨é‡æœ€é«˜çš„å›½å†…æ¨¡å‹ï¼ˆæµ‹è¯•å¾—åˆ† 98/100ï¼‰
  if (process.env.GLM_API_KEY) {
    return {
      name: 'GLM',
      apiKey: process.env.GLM_API_KEY,
      baseURL: 'https://open.bigmodel.cn/api/paas/v4',
      model: 'glm-4-plus',
      displayName: 'æ™ºè°± GLM-4-Plus',
      emoji: 'ğŸ§ ',
      features: ['å›½å†…ç›´è¿', 'è´¨é‡æœ€é«˜', '128Kä¸Šä¸‹æ–‡']
    };
  }

  // âŒ GLM ä¸å¯ç”¨æ—¶æŠ›å‡ºé”™è¯¯ï¼Œä¸å†é™çº§
  throw new AppError(
    ErrorType.API_KEY_ERROR,
    'GLM API Key æœªé…ç½®',
    {
      userMessage: 'GLM API Key æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ GLM_API_KEY ä»¥ä½¿ç”¨æ™ºè°± GLM æ¨¡å‹ã€‚ç³»ç»Ÿå·²é…ç½®ä¸ºå¼ºåˆ¶ä½¿ç”¨ GLM æ¨¡å‹ã€‚',
      context: {
        hint: 'è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GLM_API_KEY ä»¥ä½¿ç”¨æ™ºè°± GLM æ¨¡å‹',
      },
    }
  );
}

/**
 * ğŸ—ï¸ åˆ›å»º AI å®¢æˆ·ç«¯å®ä¾‹
 */
export function createAIClient(config: AIProviderConfig): OpenAI {
  console.log(`\n${'='.repeat(60)}`);
  console.log(`${config.emoji} ä½¿ç”¨ AI æœåŠ¡: ${config.displayName}`);
  console.log(`ğŸ“‹ æ¨¡å‹: ${config.model}`);
  console.log(`âœ¨ ç‰¹æ€§: ${config.features.join(' | ')}`);
  console.log(`${'='.repeat(60)}\n`);

  const clientConfig: any = {
    apiKey: config.apiKey,
  };

  if (config.baseURL) {
    clientConfig.baseURL = config.baseURL;
  }

  // ä¸º OpenAI æ·»åŠ ä»£ç†æ”¯æŒ
  if (config.name === 'OpenAI') {
    const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY;
    if (proxyUrl) {
      console.log('ğŸŒ Using proxy:', proxyUrl.replace(/\/\/[^:]+:[^@]+@/, '//***:***@'));
      clientConfig.httpAgent = new HttpsProxyAgent(proxyUrl);
    }
  }

  return new OpenAI(clientConfig);
}

/**
 * åˆ›å»º AI å®¢æˆ·ç«¯ï¼ˆæ”¯æŒåŠ¨æ€ API Key å’Œä»£ç†ï¼‰
 * æ³¨æ„ï¼šç³»ç»Ÿä½¿ç”¨æ™ºè°± GLM æ¨¡å‹ï¼Œç”¨æˆ·æä¾›çš„ API Key ä¹Ÿåº”è¯¥æ˜¯ GLM çš„
 */
export function getOpenAIClient(apiKey: string | undefined, defaultOpenai: OpenAI | null): OpenAI | null {
  if (apiKey) {
    console.log('ğŸ”‘ Using user-provided GLM API Key');
    
    // é…ç½® GLM å®¢æˆ·ç«¯ï¼ˆæ™ºè°±AIï¼‰
    const config: any = {
      apiKey,
      baseURL: 'https://open.bigmodel.cn/api/paas/v4', // GLM API åœ°å€
    };
    
    // ä»ç¯å¢ƒå˜é‡è¯»å–ä»£ç†è®¾ç½®
    const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY;
    if (proxyUrl) {
      console.log('ğŸŒ Using proxy:', proxyUrl.replace(/\/\/[^:]+:[^@]+@/, '//***:***@')); // éšè—å¯†ç 
      config.httpAgent = new HttpsProxyAgent(proxyUrl);
    }
    
    return new OpenAI(config);
  }
  return defaultOpenai;
}

/**
 * ğŸ¯ æ ¹æ®å®¢æˆ·ç«¯è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹
 */
export function getModelName(openai: OpenAI): string {
  const baseURL = (openai as any).baseURL;
  
  // DeepSeek
  if (baseURL?.includes('deepseek.com')) {
    return 'deepseek-chat';
  }
  
  // æ™ºè°± GLM
  if (baseURL?.includes('bigmodel.cn')) {
    return 'glm-4-plus';
  }
  
  // é€šä¹‰åƒé—®
  if (baseURL?.includes('dashscope.aliyuncs.com')) {
    return 'qwen-plus';
  }
  
  // OpenAIï¼ˆé»˜è®¤ï¼‰
  return 'gpt-4o';
}

/**
 * ğŸ“Š è·å–å½“å‰ä½¿ç”¨çš„ AI æä¾›å•†ä¿¡æ¯
 */
export function getProviderInfo(openai: OpenAI): string {
  const baseURL = (openai as any).baseURL;
  
  if (baseURL?.includes('deepseek.com')) return 'ğŸ”· DeepSeek';
  if (baseURL?.includes('bigmodel.cn')) return 'ğŸ§  æ™ºè°±GLM-4';
  if (baseURL?.includes('dashscope.aliyuncs.com')) return 'ğŸ‡¨ğŸ‡³ é€šä¹‰åƒé—®';
  return 'ğŸ¤– OpenAI GPT-4';
}

